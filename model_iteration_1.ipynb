{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanData(data, median_age):\n",
    "    \"\"\"\n",
    "    Take in the raw data and median age from the training data\n",
    "    and return a cleaned version for use with our model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace missing ages with the median age (from the training data!)\n",
    "    data.Age = data.Age.fillna(median_age)\n",
    "\n",
    "    # Encode male as 0 and female as 1\n",
    "    data.loc[data.Sex == 'male', 'Sex'] = 0\n",
    "    data.loc[data.Sex == 'female', 'Sex'] = 1\n",
    "\n",
    "    # Replace missing port of embarkation with Southampton\n",
    "    # Emcode Southampton as 0, Cherbourg as 1, and Queenstown as 2\n",
    "    data.Embarked = data.Embarked.fillna('S')\n",
    "    data.loc[data.Embarked == 'S', 'Embarked'] = 0\n",
    "    data.loc[data.Embarked == 'C', 'Embarked'] = 1\n",
    "    data.loc[data.Embarked == 'Q', 'Embarked'] = 2\n",
    "    \n",
    "    # Replace missing fares with the median fare\n",
    "    data.Fare = data.Fare.fillna(data.Fare.median())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('train.csv')\n",
    "titanic_test = pd.read_csv('test.csv')\n",
    "\n",
    "titanic = cleanData(titanic, titanic.Age.median())\n",
    "titanic_test = cleanData(titanic_test, titanic.Age.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use linear regression to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.339% accuracy\n"
     ]
    }
   ],
   "source": [
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = titanic.Survived.iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = sum(titanic.Survived == predictions) / len(titanic)\n",
    "print '{:.3f}% accuracy'.format(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use logistic regression to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.788% accuracy\n"
     ]
    }
   ],
   "source": [
    "# Set predictors\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic.Survived, cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print '{:.3f}% accuracy'.format(scores.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xValidateLogModel(train, predictors):\n",
    "    \"\"\"\n",
    "    Take in the training data and predictors to use\n",
    "    and return the score of the cross validation\n",
    "    \"\"\"\n",
    "    # Initialize the algorithm class\n",
    "    alg = LogisticRegression(random_state=1)\n",
    "    \n",
    "    # Cross validate using training data\n",
    "    scores = cross_validation.cross_val_score(alg, train[predictors], train.Survived, cv=3)\n",
    "    \n",
    "    # Return the mean of the 3 scores\n",
    "    return scores.mean()\n",
    "\n",
    "def testLogModel(train, test, predictors):\n",
    "    \"\"\"\n",
    "    Take in the training data, testing data, and predictors to use\n",
    "    and return the submission dataframe for a logistic regression model\n",
    "    \"\"\"\n",
    "    # Initialize the algorithm class\n",
    "    alg = LogisticRegression(random_state=1)\n",
    "    \n",
    "    # Train the algorithm using all the training data\n",
    "    alg.fit(train[predictors], train.Survived)\n",
    "\n",
    "    # Make predictions using the test set.\n",
    "    predictions = alg.predict(test[predictors])\n",
    "\n",
    "    # Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "    return pd.DataFrame({\n",
    "        'PassengerId': test.PassengerId,\n",
    "        'Survived': predictions\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set predictors\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Test model\n",
    "submission = testLogModel(titanic, titanic_test, predictors)\n",
    "\n",
    "# Write submission to a CSV file\n",
    "submission.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75.120% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second model iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A change I would like to make to the model is to ignore the port of embarkation.  It doesn't seem like this factor should influence a passenger's survival.  When exploring the data, I did find that there was a difference in survival rates between the ports, but I hypothesize that this has to do with the percentages of upper class, female, and child passengers from each place rather than anything about the port itself.  So, it seems odd to me to include the port of embarkation in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.012% accuracy\n"
     ]
    }
   ],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "score = xValidateLogModel(titanic, predictors)\n",
    "print '{:.3f}% accuracy'.format(score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation shows a slight improvement, so let's try it on the test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "submission = testLogModel(titanic, titanic_test, predictors)\n",
    "submission.to_csv('submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "74.163% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the cross validation with the training data showed an improvement, the model performed worse with the test data. I'm a bit confused as to why this may be.  Does having the port of embarkation included give more weight to the underlying factors that differentiate the ports (proportions of class, sex, age, etc.)?  If so, why doesn't the model give these factors an appropriate weighting when the port information is removed?  If not, why _is_ the port of embarkation information being useful when my intuition is saying that it should not be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third model iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something else seen when exploring the data is that young children tended to survive regardless of gender.  By adding a flag for young children, I hope to bring this out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.471% accuracy\n"
     ]
    }
   ],
   "source": [
    "titanic.loc[titanic.Age <= 8, 'IsChild'] = 1\n",
    "titanic.loc[titanic.Age > 8, 'IsChild'] = 0\n",
    "titanic_test.loc[titanic_test.Age <= 8, 'IsChild'] = 1\n",
    "titanic_test.loc[titanic_test.Age > 8, 'IsChild'] = 0\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"IsChild\"]\n",
    "score = xValidateLogModel(titanic, predictors)\n",
    "print '{:.3f}% accuracy'.format(score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is showing a greater improvement than the last iteration, but let's see if it can improve with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"IsChild\"]\n",
    "submission = testLogModel(titanic, titanic_test, predictors)\n",
    "submission.to_csv('submission_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76.555% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It did improve!  The new model was able to guess correctly for 6 more of the test passengers than in the initial iteration.  Honestly, I'm not entirely sure why this improved the model.  Perhaps a logistic regression cannot deal with a step, like the one in the survival rate of males between children and adults, and adding a feature that reflects the step helped?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
