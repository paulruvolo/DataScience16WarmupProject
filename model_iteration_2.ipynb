{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read through both Dataquest tutorials, as well as some more tutorials on the kaggle forums. All of them seemed to revolve around using the same variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using age, like most of the tutorials, I've turned that continuous variable into a discrete 'Adult' variable, based on whether a passenger was 16 or older. I use a FamilySize variable that is the sum of SibSp and Parch, and I've turned the Embarked and Sex categories into integers instead of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas, math\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "titanic = pandas.read_csv('train.csv')\n",
    "titanic_test = pandas.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up data, replace strings with integers, create new variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create FamSize variable as sum of Parch and SibSp values\n",
    "titanic['FamSize'] = titanic.SibSp + titanic.Parch\n",
    "titanic_test['FamSize'] = titanic_test.SibSp + titanic_test.Parch\n",
    "\n",
    "#Replace male/female strings with 0/1\n",
    "titanic.Sex.replace(['male', 'female'], [0, 1], inplace=True)\n",
    "titanic_test.Sex.replace(['male', 'female'], [0, 1], inplace=True)\n",
    "\n",
    "#Fill empty values with the median age of the data\n",
    "titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())\n",
    "titanic_test['Age'] = titanic_test['Age'].fillna(titanic['Age'].median())\n",
    "\n",
    "#Create a variable which transforms age to log(age)\n",
    "titanic['LogAge'] = titanic['Age'].apply(lambda x: math.log(x))\n",
    "titanic_test['LogAge'] = titanic_test['Age'].apply(lambda x: math.log(x))\n",
    "\n",
    "#Create a variable that is the length of a passenger's name\n",
    "titanic['NameLen'] = titanic['Name'].apply(lambda x: len(x))\n",
    "titanic_test['NameLen'] = titanic['Name'].apply(lambda x: len(x))\n",
    "\n",
    "#Fill in missing Fare values with median value\n",
    "titanic_test['Fare'].fillna(titanic_test['Fare'].median(), inplace=True)\n",
    "\n",
    "#Create Adult variable based on whether a passenger's age is greater/less than 16\n",
    "titanic['Adult'] = titanic['Age'].apply(lambda(x): 0 if x<16.0 else 1)\n",
    "titanic_test['Adult'] = titanic_test['Age'].apply(lambda(x): 0 if x<16.0 else 1)\n",
    "\n",
    "#Fill missing embarked values with most common part\n",
    "titanic.Embarked.fillna('S', inplace=True)\n",
    "titanic_test.Embarked.fillna('S', inplace=True)\n",
    "\n",
    "#Replace string values of ports with ints\n",
    "titanic['Embarked'].replace(['S', 'C', 'Q'], [0, 1, 2], inplace=True)\n",
    "titanic_test['Embarked'].replace(['S', 'C', 'Q'], [0, 1, 2], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a logistic regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79012345679\n"
     ]
    }
   ],
   "source": [
    "predictors = [\"Sex\", \"Adult\", \"Embarked\", \"FamSize\"]\n",
    "alg = LogisticRegression(random_state=1)\n",
    "#Test Logistic regression model with given predictors and print score\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824915824916\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=120, min_samples_split=3, min_samples_leaf=4)\n",
    "#Test Random Forest model with given predictors and print score\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Besides using different variables as parameters in the Random Forest, I also tried to modify the parameters of the Random Forest, to little effect. The most dramatic effect was in modifying the number of estimators, and it almost always worsened the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "#Create a submission using alg and predictors, export to csv\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score = .78469 using a Random Forest with Sex, Adult, Embarked, FamSize, 120 estimators, minimum split of 3, minimum sample of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79797979798\n"
     ]
    }
   ],
   "source": [
    "#Ensembling code pulled straight from tutorial\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), predictors]\n",
    "]\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "print(scores.mean())\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions[predictions>.5] = 1\n",
    "predictions[predictions<=.5] =  0\n",
    "predictions = predictions.astype(int)\n",
    "submission = pandas.DataFrame({'PassengerId': titanic_test['PassengerId'], 'Survived':predictions})\n",
    "submission.to_csv(\"kaggle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score = .78947 using an ensemble of Gradient Boosting and Logistic Regression. Parameters were Sex, Adult, Embarked, FamSize, and Pclass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was very difficult to correlate an improvement in training data score with a correlation in kaggle submission scores. When I was using the Random Forest, reducing the number of parameters almost always gave a better performance (up to a point). This makes sense because I think complex models tend to overfit to the training data. I also just read The Evolution of Cooperation by Robert Axelrod, and that book gives plenty of examples for why models should be as simple as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
